{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "# extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "-  0 : artist \n",
    "-  1 : firstName of user\n",
    "-  2 : gender of user\n",
    "-  3 : item number in session\n",
    "-  4 : last name of user\n",
    "-  5 : length of the song\n",
    "-  6 : level (paid or free song)\n",
    "-  7 : location of the user\n",
    "-  8 : sessionId\n",
    "-  9 : song title\n",
    "- 10 : userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us make a connection to a Cassandra instance the local machine: (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "try: \n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will create a KEYSPACE : First we will check 'IF NOT EXISTS' an then create a KeySpace as 'udacity'; to check if a keyspace with the same name already exists\n",
    "# We are using REPLICATION class as 'SimpleStrategy' and 'replication_factor' as 1 which creates as keyspace for a single node evaluation cluster\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will Set KEYSPACE as 'udacity' which was created above using 'set_keyspace()'\n",
    "\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  __Question-1 :__ Give me the artist, song title and song's length in music app history that was heard during sessionId=338,  itemInSession=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our objective is to find artist, song title and song's length based on sessionId and itemInSession; First we need to think create a table based on the query we are going to use.\n",
    "# Before creating, DROP the Table if it exists so that we can quickly regenerate the table if needed by executing this cell.\n",
    "query = \"DROP TABLE IF EXISTS song_session \"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Let's Create a Table `music_library` with PRIMARY KEY sessionId and itemInSession(as we need to query based on sessionId and itemInSession ) \n",
    "# And artist name, song title and song's length which we need to find. We will set the datatypes as per the event_datafile_new.csv, ie: sessionId as int\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_session \"\n",
    "query = query + \"(sessionId int, itemInSession int, artist_name text, song_title text, song_length float, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will load the csv file and insert sessionId ,itemInSession ,artist_name ,song_title ,song_length into music_library by iterating through each row\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # this skips the header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_session (sessionId , itemInSession , artist_name , song_title , song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\" # This is the INSERT query to insert values into TABLE : music_library\n",
    "        ## Now will pass the values to the INSERT statement for each row; we will select values as line[index] and set values based on dtype.eg: for int int(line[index])\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5]))) #This will execute the query above and INSERT the values in the music_library Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist name: Faithless, Song name: Music Matters (Mark Knight Dub), Song length: 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "## Verify if Records were added to music_library using a SELECT statement : we will execute the query as asked in Q1\n",
    "\n",
    "query = \"SELECT artist_name , song_title , song_length FROM song_session WHERE sessionId = 338 and itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(\"Artist name: {}, Song name: {}, Song length: {}\".format(row.artist_name, row.song_title, row.song_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 1:__\n",
    "\n",
    "\n",
    "The Question 1 expects Name of the artist, title of the song and length of the track based on sessionId and itemInSession.\n",
    "As we are working with a NoSQL database, we need to think about the query first which will be used to fetch the data based on which we will create the Table required.\n",
    "\n",
    "1. The expected output is : \"Name of the artist, title of the song and length of the track\"\n",
    "2. Based on : \"sessionId and itemInSession\"\n",
    "\n",
    "From the above two points we know the query to get the data will be a SELECT statement like :\n",
    "\n",
    "`SELECT Name of the artist, title of the song, length of the track FROM TABLE_NAME WHERE sessionId = value AND itemInSession = value`\n",
    "\n",
    "As we know the `SELECT` query, we can move to `CREATE` table query. We will add `NOT EXIST` to the CREATE statement to check if the table exists and only create the table if it does not exist. Now we need to select the columns that are going to be in the table and the PRIMARY KEY.(Named: song_session as per Rubric requirements for tables names as alphanumeric; also as the details of the table is for songs, it sounds apt to name the table 'song_session') \n",
    "\n",
    "* Column Names: We need Name of the artist, title of the song and length of the track on query upon sessionId and itemInSession. Hence we will select artist_name , song_title , song_length, sessionId and itemInSession as the name of the columns.\n",
    "* Primary Key: The PRIMARY key for the table should uniquely identify each row in the table. For us we need results based on sessionId and itemInSession; so we neeed these both as the primary key (*Selecting one will throw filtering error on \"SELECT * FROM song_session WHERE sessionId = 338 and itemInSession = 4\", as we have not set itemInSession in primary key; also filtering is not allowed for the project)*\n",
    "\n",
    "---\n",
    "\n",
    "Now, as we have the columns we want and the Primary Key, we can go ahead with creating the table with CREATE statement as:\n",
    "\n",
    "\n",
    "```\n",
    "CREATE TABLE IF NOT EXISTS song_session (sessionId int,\n",
    "                                            itemInSession int, \n",
    "                                            artist_name text, \n",
    "                                            song_title text, \n",
    "                                            song_length float, \n",
    "                                            PRIMARY KEY (sessionId, itemInSession))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "   Important things to notice here are the data types for each attribute. From the above `event_datafile_new.csv` we can see the various datatypes. Also we can find a particular data type as: `df = pd.read_csv('event_datafile_new.csv'); df.dtypes` which will give data types for all the columns based on which we will set the dtype for each of our attributes in the CREATE statement. Another crucial point here is that Apache Cassandra is a partition row store, which means the data should be Inserted and Retrieved in the order of the primary key (in our case the Composite Primary Key). Our CREATE statement and also the INSERT statement has been made with keeping this in mind.\n",
    "\n",
    "---\n",
    "\n",
    "   Once the table is created, the next step is inserting the data into the table from the csv file: Our INSERT statement will iterate through each row of the CSV file(*line*) and Insert the data from the appropriate columns to our table columns. For eg: For the `sessionId` the CSV file has the column at index 8, so for the `song_session's sessionId` we will take the value from: current row which is `line` and its 9th column which is `line[8]` : `int(line[8]`. The int here is so that data type matches our table column data-type. Similarly we have used float dtype for song_length which is a float value.\n",
    "\n",
    "---\n",
    "\n",
    "   Once the data has been inserted, we need to verify the insertion by retriving : a `SELECT` statement. We are using our Question's selection statemnet based on which we created this table:  `\"SELECT artist_name , song_title , song_length FROM song_session WHERE sessionId = 338 and itemInSession = 4\"`\n",
    "\n",
    "The output is a single record : `Faithless Music Matters (Mark Knight Dub) 495.30731201171875` : This means our operation was successful.\n",
    "\n",
    "---\n",
    "\n",
    "__Summary:__ Here we can see that the Artist's name is `Faithless`, Song's name is `Music Matters (Mark Knight Dub)` and the song's Length is `495.30731201171875`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Question-2:__ Give me only the following: name of artist, song(sorted by itemInSession), user(first and last name) for userid=10, sessionid=182                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE IF EXISTS song_playlist_session \" #To DROP TABLE IF EXISTS:\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "    \n",
    "query = \"CREATE TABLE IF NOT EXISTS song_playlist_session \"\n",
    "query = query+\"(userid int, sessionid int, item_in_session int, artist_name text,  song_title text, user_firstName text, user_lastName text, PRIMARY KEY ((userid, sessionid), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_playlist_session (userid , sessionid, item_in_session, artist_name,  song_title, user_firstName , user_lastName)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist Name: Down To The Bone, Song Name: Keep On Keepin' On, User Name: Sylvie Cruz, itemInSession: 0\n",
      "Artist Name: Three Drives, Song Name: Greece 2000, User Name: Sylvie Cruz, itemInSession: 1\n",
      "Artist Name: Sebastien Tellier, Song Name: Kilometer, User Name: Sylvie Cruz, itemInSession: 2\n",
      "Artist Name: Lonnie Gordon, Song Name: Catch You Baby (Steve Pitron & Max Sanna Radio Edit), User Name: Sylvie Cruz, itemInSession: 3\n"
     ]
    }
   ],
   "source": [
    "query = \"select * from song_playlist_session WHERE userid = 10 and sessionid = 182 \"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(\"Artist Name: {}, Song Name: {}, User Name: {} {}, itemInSession: {}\".format(row.artist_name, row.song_title, row.user_firstname, row.user_lastname, row.item_in_session))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "\n",
    "__Answer 2:__\n",
    "    \n",
    "The question here is similar to the Q1 with a few tweaks: We need name of artist, song name, user(first and last name) for userid=10, sessionid=182. However, we need to sort the song name by item_in_session. This means we need a COMPOSITE PRIMARY KEY with `item_in_session` as the CLUSTERING KEY. We will think about the query on which we need to create the table. The query will be something like: \"SELECT artist_name, song_title, user_firstname, user_lastname FROM TABLE WHERE userid=10 and sessionid=182\"\n",
    "\n",
    "Now lets create a tabel for this: userid, sessionid, artist_name, song_title, user_firstname, user_lastname will be columns with (userid, sessionid) as a composite PRIMARY KEY where `userid` is the PARTITION KEY and `sessionid` is the CLUSTERING KEY. Here `(userid, sessionid)` will be our `PARTITION KEY`. Data types will be appropriately assigned to each column names as explained in Question 1.\n",
    "\n",
    "The INSERT query is build similar to as in Q1 with keeping in mind the sequence order for Data Partition.\n",
    "\n",
    "The data is fetched from the CSV file same as explained above keeping in mind the data types for each attribute.\n",
    "\n",
    "The SELECT query fetches the values asked in Question 2 while sorting is done on `item_in_session`:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "<ARTIST>                    <SONG>                                         <First NAME>   <LAST NAME>    <itemInSession>\n",
    "Down To The Bone       Keep On Keepin' On                                    Sylvie          Cruz              0\n",
    "Three Drives           Greece 2000                                           Sylvie          Cruz              1\n",
    "Sebastien Tellier      Kilometer                                             Sylvie          Cruz              2\n",
    "Lonnie Gordon          Catch You Baby(Steve Pitron & Max Sanna Radio Edit)  Sylvie           Cruz              3\n",
    "```\n",
    "\n",
    "__From above, we see that the user(10) had listened to four songs during the session 182.__\n",
    "\n",
    "----------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Question-3:__ Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE IF EXISTS user_session\" #DROP TABLE IF EXISTS:\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "    \n",
    "query = \"CREATE TABLE IF NOT EXISTS user_session \"\n",
    "query = query + \"(song_title text, userid int, user_firstName text, user_lastName text, PRIMARY KEY (song_title, userid))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_session (song_title, userid , user_firstName , user_lastName)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Name: Jacqueline Lynch\n",
      "User Name: Tegan Levine\n",
      "User Name: Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"select user_firstname, user_lastname from user_session WHERE song_title = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (\"User Name: {} {}\".format(row.user_firstname, row.user_lastname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "__Answer:__\n",
    "\n",
    "Here we need first and last name of every user who listened to a aprticular song, so our query will be \"select user_firstname, user_lastname from TABLE WHERE song_title = abc\".\n",
    "So we can create a TABLE with song_title, user_firstname, user_lastname and PRIMARY KEY as \"(song_title, user_firstname)\". However, the problem with this is First Names are common and there might be other people with same first name, same goes for the last name. Hence, it is better if we consider a different value which is unique: I have selected userid which seems to be unique. Thus we have a table with COMPOSITE PRIMARY KEY (song_title, userid).\n",
    "\n",
    "We will INSERT the data same way as the previous questions. The Retrival query will select all users who hve listened to the song 'All Hands Against His Own' which was the objective of the question.\n",
    "\n",
    "From the output we can see that there are three users who listen to the song \"All Hands Against His Own\", and they are:\n",
    "\n",
    "```\n",
    "Jacqueline   Lynch\n",
    "Tegan        Levine\n",
    "Sara         Johnson\n",
    "```\n",
    "\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we will drop all three tables with DROP TABLE statements(We will use IF EXIST condition).\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS song_session\" #DROP TABLE: song_session IF EXISTS:\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS song_playlist_session\" #DROP TABLE: song_playlist_session IF EXISTS:\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "\n",
    "query = \"DROP TABLE IF EXISTS user_session\" #DROP TABLE: user_session IF EXISTS:\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown() # Closes the session\n",
    "cluster.shutdown() # # Closes the cluster connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
